# -*- coding: utf-8 -*-
"""retrain icmp_flood_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vnlxk2S25caljoDe4vTOKuWQJUMGDExa
"""

##import thư viện cần thiết
import pandas as pd
import numpy as np
import re
import ipaddress

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

from google.colab import drive

# Mount Google Drive vào hệ thống colab
drive.mount('/content/drive')

file_path = '/content/drive/My Drive/icmp_flood.csv'

# Đọc file CSV để kiểm tra
df = pd.read_csv(file_path)
print("Đã load file CSV.")

# Đếm tổng số dòng
total_rows= df.shape[0]
print(f"Tổng số gói tin icmp_flood trong tệp dataset mới là: {total_rows}")

#copy lai danh sach goc
original_df = df.copy()

# Function to convert IP address to integer
def ip_to_int(ip_str):
    try:
        return int(ipaddress.IPv4Address(ip_str))
    except ValueError:
        return int(ipaddress.IPv4Address("0.0.0.0"))

# Áp dụng chuyển đổi địa chỉ IP nguồn và đích
df['src_ip'] = df['src_ip'].apply(ip_to_int)
df['dst_ip'] = df['dst_ip'].apply(ip_to_int)

# Extract information from 'icmp_info' column
def extract_icmp_info(info):
    match = re.search(r'id=0x([0-9a-fA-F]+), seq=(\d+)/(\d+), ttl=(\d+)', info)
    if match:
        icmp_id = int(match.group(1), 16)
        seq1 = int(match.group(2))
        seq2 = int(match.group(3))
        ttl = int(match.group(4))
        return icmp_id, seq1, seq2, ttl
    else:
        return 0, 0, 0, 0

# Custom normalization function
def normalize(data, min_vals, max_vals):
    return (data - min_vals.values) / (max_vals.values - min_vals.values)

# Tạo các cột mới từ thông tin ICMP
icmp_ids = []
seq1s = []
seq2s = []
ttls = []

for info in df['icmp_info']:
    icmp_id, seq1, seq2, ttl = extract_icmp_info(info)
    icmp_ids.append(icmp_id)
    seq1s.append(seq1)
    seq2s.append(seq2)
    ttls.append(ttl)

df['icmp_id'] = icmp_ids
df['seq1'] = seq1s
df['seq2'] = seq2s
df['ttl'] = ttls

# Loại bỏ cột 'index' và tính giá trị tối thiểu và tối đa cho mỗi cột còn lại
min_vals = df[['time', 'src_ip', 'dst_ip', 'size', 'icmp_id', 'seq1', 'seq2', 'ttl']].min()
max_vals = df[['time', 'src_ip', 'dst_ip', 'size', 'icmp_id', 'seq1', 'seq2', 'ttl']].max()
# Chuẩn hóa dữ liệu
normalized_data = normalize(df[['time', 'src_ip', 'dst_ip', 'size', 'icmp_id', 'seq1', 'seq2', 'ttl']], min_vals, max_vals)
data_tensor = torch.tensor(normalized_data.values, dtype=torch.float32)

class Generator(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(Generator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.LeakyReLU(0.2),
            nn.BatchNorm1d(256),
            nn.Linear(256, 512),
            nn.LeakyReLU(0.2),
            nn.BatchNorm1d(512),
            nn.Linear(512, 1024),
            nn.LeakyReLU(0.2),
            nn.BatchNorm1d(1024),
            nn.Linear(1024, output_dim),
            nn.Tanh()
        )

    def forward(self, x):
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self, input_dim):
        super(Discriminator, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 1024),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(1024, 512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.3),
            nn.Linear(256, 1),
            nn.Sigmoid()
        )

    def forward(self, x):
        return self.model(x)

# Các tham số cho mô hình
input_dim = 100  # Đầu vào của Generator
output_dim = data_tensor.shape[1]  # Số cột của dữ liệu
lr = 0.0001  # Learning rate
epochs = 10000
batch_size = min(128, data_tensor.shape[0])

# Khởi tạo Generator và Discriminator
generator = Generator(input_dim, output_dim)
discriminator = Discriminator(output_dim)

# Định nghĩa loss function và optimizer
criterion = nn.BCELoss()
optimizer_G = optim.Adam(generator.parameters(), lr=lr)
optimizer_D = optim.Adam(discriminator.parameters(), lr=lr)

# Định nghĩa hàm train_gan
def train_gan():
    for epoch in range(epochs):
        # Huấn luyện Discriminator
        idx = np.random.randint(0, data_tensor.shape[0], batch_size)
        real_data = data_tensor[idx]
        real_labels = torch.ones(batch_size, 1)

        noise = torch.randn(batch_size, input_dim)
        fake_data = generator(noise)
        fake_labels = torch.zeros(batch_size, 1)

        optimizer_D.zero_grad()
        real_loss = criterion(discriminator(real_data), real_labels)
        fake_loss = criterion(discriminator(fake_data), fake_labels)
        d_loss = real_loss + fake_loss
        d_loss.backward()
        optimizer_D.step()

        # Huấn luyện Generator
        optimizer_G.zero_grad()
        noise = torch.randn(batch_size, input_dim)
        gen_labels = torch.ones(batch_size, 1)
        g_loss = criterion(discriminator(generator(noise)), gen_labels)
        g_loss.backward()
        optimizer_G.step()

        # In ra tiến trình huấn luyện
        if epoch % 1000 == 0:
            print(f"{epoch}/{epochs} [D loss: {d_loss.item()}] [G loss: {g_loss.item()}]")

    return generator,discriminator

# Huấn luyện mô hình GAN
generator,discriminator= train_gan()

# Tạo dữ liệu giả sau khi huấn luyện
num_samples = 100000
noise = torch.randn(num_samples, input_dim)
generated_data = generator(noise).detach().numpy()

# Custom denormalization function
def denormalize(data, min_vals, max_vals):
    return data * (max_vals.values - min_vals.values) + min_vals.values

# Convert IP integers back to IP addresses
def int_to_ip(ip_int):
    try:
        return str(ipaddress.IPv4Address(int(ip_int)))
    except ValueError:
        return "0.0.0.0"

# Create 'icmp_info' column from 'icmp_id', 'seq1', 'seq2', and 'ttl' and round these values
def create_icmp_info(icmp_id, seq1, seq2, ttl):
    return f"Echo (ping) request  id=0x{int(icmp_id):x}, seq={int(seq1)}/{int(seq2)}, ttl={int(ttl)}  (no response found!)"

# Denormalize the generated data
denormalized_data = denormalize(generated_data, min_vals, max_vals)
denormalized_df = pd.DataFrame(denormalized_data, columns=['time', 'src_ip', 'dst_ip', 'size', 'icmp_id', 'seq1', 'seq2', 'ttl'])
# Xóa các hàng có giá trị thời gian bị âm
denormalized_df['src_ip'] = denormalized_df['src_ip'].apply(int_to_ip)
denormalized_df['dst_ip'] = denormalized_df['dst_ip'].apply(int_to_ip)
# Ensure dst_ip column has the same values as original df
denormalized_df['dst_ip'] = df['dst_ip'].iloc[:num_samples].apply(int_to_ip).values
# Include the 'protocol' column with constant value 'ICMP'
denormalized_df['protocol'] = 'ICMP'
# Round values for 'time' and 'size'
denormalized_df['time'] = denormalized_df['time'].round(6)
denormalized_df['size'] = denormalized_df['size'].round()
denormalized_df['icmp_info'] = denormalized_df.apply(lambda row: create_icmp_info(row['icmp_id'], row['seq1'], row['seq2'], row['ttl']), axis=1)
denormalized_df.drop(columns=['icmp_id', 'seq1', 'seq2', 'ttl'], inplace=True)
# Sắp xếp kết quả theo thứ tự tăng dần của cột 'time'
denormalized_df = denormalized_df[denormalized_df['time'] >= 0]
denormalized_df.sort_values(by='time', inplace=True)

# Select and print the desired columns
selected_columns_flood1  = denormalized_df[['time', 'src_ip', 'dst_ip', 'protocol', 'size', 'icmp_info']]
print("Mẫu thử được tạo ra từ GANS:")
print(selected_columns_flood1 )

# Ghép dữ liệu gốc và dữ liệu giả
combined_df = pd.concat([original_df, selected_columns_flood1], ignore_index=True)
print(combined_df.tail(10000))

# Lưu lại DataFrame mới vào tệp CSV
combined_df.to_csv(file_path, index=False)
# Đếm tổng số dòng
total_rows= combined_df.shape[0]
print(f"Tổng số dòng trong tệp CSV là: {total_rows}")

"""real_data_tensor được gán giá trị từ data_tensor chứa dữ liệu thực tế
denormalized_data là dữ liệu giả đã được khôi phục từ dạng chuẩn hóa về giá trị ban đầu
"""

real_data_tensor = data_tensor
fake_data_tensor = torch.tensor(denormalized_data, dtype=torch.float32)

# Định nghĩa hàm đánh giá các chỉ số
def evaluate_model(discriminator, real_data, fake_data):
    real_labels = torch.ones(real_data.size(0), 1)
    fake_labels = torch.zeros(fake_data.size(0), 1)

    with torch.no_grad():
        real_predictions = discriminator(real_data).numpy()
        fake_predictions = discriminator(fake_data).numpy()
    print("Real Labels:", real_labels.numpy())
    print("Fake Labels:", fake_labels.numpy())
    print("Real Predictions:", real_predictions)
    print("Fake Predictions:", fake_predictions)

    all_predictions = np.concatenate((real_predictions, fake_predictions), axis=0)
    all_labels = np.concatenate((real_labels.numpy(), fake_labels.numpy()), axis=0)
    print("Tất cả đự đoán:", all_predictions)
    print("Tất cả nhãn:", all_labels)
    all_predictions = (all_predictions > 0.5).astype(int)
    print("Tất cả đự đoán trên 0.5 thành 1 và dưới 0.5 thanh 0:", all_predictions)
    tp = np.sum((all_predictions == 1) & (all_labels == 1))
    print(f"Tổng số mẫu icmp flood được dụ đoán dựa vào dataset: {tp:.4f}")
    tn = np.sum((all_predictions == 0) & (all_labels == 0))
    print(f"Tổng số mẫu icmp được dự đoán do generator : {tn:.4f}")
    fp = np.sum((all_predictions == 1) & (all_labels == 0))
    print(f" Tổng số mẫu icmp dự đoán sai do generator :{fp :.4f}")
    fn = np.sum((all_predictions == 0) & (all_labels == 1))
    print(f"Tổng số mẫu icmp dự đóa. sai dựa trên dataset  : {fn:.4f}")


    accuracy = (tp + tn) / (tp + tn + fp + fn)
    precision = tp / (tp + fp) if tp + fp > 0 else 0
    recall = tp / (tp + fn) if tp + fn > 0 else 0
    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0

    return accuracy, precision, recall, f1

# Đánh giá mô hình
accuracy, precision, recall, f1 = evaluate_model(discriminator, real_data_tensor, fake_data_tensor)

print(f"Độ chính xác (Accuracy) của mô hình  trên tổng số mẫu: {accuracy:.4f}")
print(f"Tỷ lệ dự đoán đúng (Precision) trên tổng số dự đoán dương: {precision:.4f}")
print(f"Tỷ lệ dự đoán đúng (Recall) trên tổng số trường hợp dương thực tế: {recall:.4f}")
print(f"Trung bình điều hòa của Precision và Recall (F1 Score): {f1:.4f}")